
<!DOCTYPE html>

<html lang="pl">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Wstęp &#8212; Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/koh.png"/>
    <link rel="index" title="Indeks" href="../genindex.html" />
    <link rel="search" title="Szukaj" href="../search.html" />
    <link rel="next" title="MCP Neuron" href="mcp.html" />
    <link rel="prev" title="Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="pl">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/koh.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Przeszukaj tę książkę ..." aria-label="Przeszukaj tę książkę ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Wstęp
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mcp.html">
   MCP Neuron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="memory.html">
   Models of memory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="perceptron.html">
   Perceptron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="more_layers.html">
   More layers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="backprop.html">
   Back propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interpol.html">
   Interpolation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rectification.html">
   Rectification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="unsupervised.html">
   Unsupervised learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="som.html">
   Self Organizing Maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="conclusion.html">
   Concluding remarks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="appendix.html">
   Dodatki
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Przełącz nawigację" aria-controls="site-navigation"
                title="Przełącz nawigację" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Pobierz tę stronę"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/intro.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Pobierz plik źródłowy" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Drukuj do PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/bronwojtek/nn_polish/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repozytorium źródłowe"><i
                    class="fab fa-github"></i>magazyn</button></a>
        <a class="issues-button"
            href="https://github.com/bronwojtek/nn_polish//issues/new?title=Issue%20on%20page%20%2Fdocs/intro.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Otwórz problem"><i class="fas fa-lightbulb"></i>otwarty problem</button></a>
        <a class="edit-button" href="https://github.com/bronwojtek/nn_polish/edit/master/nn_polish/docs/intro.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edytuj tę strone"><i class="fas fa-pencil-alt"></i>zaproponuj edycję</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Pełny ekran"
        title="Pełny ekran"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/bronwojtek/nn_polish/master?urlpath=tree/nn_polish/docs/intro.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Uruchomić Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Zawartość
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cel-wykladu">
   Cel wykładu
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inspiracja-biologiczna">
   Inspiracja biologiczna
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sieci-feed-forward">
   Sieci feed-forward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dlaczego-python">
   Dlaczego Python
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#importowane-pakiety">
     Importowane pakiety
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Wstęp</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Zawartość </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cel-wykladu">
   Cel wykładu
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inspiracja-biologiczna">
   Inspiracja biologiczna
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sieci-feed-forward">
   Sieci feed-forward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dlaczego-python">
   Dlaczego Python
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#importowane-pakiety">
     Importowane pakiety
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="wstep">
<h1>Wstęp<a class="headerlink" href="#wstep" title="Stały odnośnik do tego nagłówka">¶</a></h1>
<div class="section" id="cel-wykladu">
<h2>Cel wykładu<a class="headerlink" href="#cel-wykladu" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Celem kursu jest wyłożenie podstaw wszechobecnych sieci neuronowych z pomocą <a class="reference external" href="https://www.python.org/">Pythona</a> <span id="id1">[<a class="reference internal" href="conclusion.html#id5" title="P. Barry. Head First Python: A Brain-Friendly Guide. O'Reilly Media, 2016. ISBN 9781491919491. URL: https://books.google.pl/books?id=NIqNDQAAQBAJ.">Bar16</a>, <a class="reference internal" href="conclusion.html#id3" title="John Guttag. Introduction to computation and programming using Python: With application to understanding data. MIT Press, 2016.">Gut16</a>, <a class="reference internal" href="conclusion.html#id2" title="E. Matthes. Python Crash Course, 2nd Edition: A Hands-On, Project-Based Introduction to Programming. No Starch Press, 2019. ISBN 9781593279295. URL: https://books.google.pl/books?id=boBxDwAAQBAJ.">Mat19</a>]</span>. Zarówno kluczowe pojęcia sieci neuronowych, jak i programy ilustrujące są wyjaśniane na bardzo podstawowym poziomie, niemal „licealnym”. Kody, bardzo proste, zostały szczegółowo opisane. Ponadto są utworzone bez użycia specjalistycznych bibliotek wyższego poziomu dla sieci neuronowych, co pomaga w lepszym zrozumieniu przedstawionych algorytmów i pokazuje, jak programować je od podstaw.</p>
<div class="important admonition">
<p class="admonition-title">Dla kogo jest ta książka?</p>
<p><strong>Czytelnik może być zupełnym nowicjuszem, tylko w niewielkim stopniu zaznajomionym z Pythonem (a właściwie każdym innym językiem programowania) i Jupyterem.</strong></p>
</div>
<p>Materiał obejmuje takie klasyczne zagadnienia, jak perceptron i jego najprostsze zastosowania, nadzorowane uczenie z propagacją wsteczną do klasyfikacji danych, uczenie nienadzorowane i klasteryzacja, sieci samoorganizujące się Kohonena oraz sieci Hopfielda ze sprzężeniem zwrotnym. Ma to na celu przygotowanie niezbędnego gruntu dla najnowszych i aktualnych postępów (nie omówionych tutaj) w sieciach neuronowych, takich jak uczenie głębokie, sieci konwolucyjne, sieci rekurencyjne, generatywne sieci przeciwników, uczenie ze wzmacnianiem itp.</p>
<p>W trakcie kursu nowicjuszom zostanie delikatnie przemycone kilka podstawowych programów w Pythonie. W kodach znajdują się objaśnienia i komentarze.</p>
<div class="warning admonition">
<p class="admonition-title">Ćwiczenia</p>
<p>Na końcu każdego rozdziału proponujemy kilka ćwiczeń, których celem jest zapoznanie czytelnika z poruszanymi tematami i kodami. Większość ćwiczeń polega na prostych modyfikacjach/rozszerzeniach odpowiednich fragmentów materiału wykładowego.</p>
</div>
<div class="note admonition">
<p class="admonition-title">Literatura</p>
<p>Podręczników i notatek do wykładów poświęconych zagadnieniom poruszanym na tym kursie jest niezliczona ilość, stąd autor nie będzie próbował przedstawiać nawet niepełnego spisu literatury. Przytaczamy tylko pozycje, na które może spojrzeć bardziej zainteresowany czytelnik.</p>
</div>
<p>Z prostotą jako drogowskazem, wybór tematów był inspirowany szczegółowymi wykładami <a class="reference external" href="http://vision.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5038WF2014/IntroNeuralSyllabus.html">Daniela Kerstena</a> w programie Mathematica, z internetowej książki <a class="reference external" href="https://page.mi.fu-berlin.de/rojas/neural/">Raula Rojasa</a> (dostępna również w wersji drukowanej <span id="id2">[<a class="reference internal" href="conclusion.html#id8" title="J. Feldman and R. Rojas. Neural Networks: A Systematic Introduction. Springer Berlin Heidelberg, 2013. ISBN 9783642610684.">FR13</a>]</span>) oraz z punktu widzenia <strong>fizyków</strong> (jak ja!) z <span id="id3">[<a class="reference internal" href="conclusion.html#id7" title="B. Müller, J. Reinhardt, and M.T. Strickland. Neural Networks: An Introduction. Physics of Neural Networks. Springer Berlin Heidelberg, 2012. ISBN 9783642577604. URL: https://books.google.pl/books?id=on0QBwAAQBAJ.">MullerRS12</a>]</span>.</p>
</div>
<div class="section" id="inspiracja-biologiczna">
<h2>Inspiracja biologiczna<a class="headerlink" href="#inspiracja-biologiczna" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Inspiracją do opracowania matematycznych modeli obliczeniowych omawianych w tym kursie jest struktura biologiczna naszego układu nerwowego <span id="id4">[<a class="reference internal" href="conclusion.html#id6" title="E.R. Kandel, J.H. Schwartz, T.M. Jessell, S.A. Siegelbaum, and A.J. Hudspeth. Principles of Neural Science, Fifth Edition. McGraw-Hill Education, 2012. ISBN 9780071810012. URL: https://books.google.pl/books?id=Z2yVUTnlIQsC.">KSJ+12</a>]</span>. Centralny układ nerwowy (mózg) zawiera ogromną liczbę (<span class="math notranslate nohighlight">\(\sim 10^{11}\)</span>) <a class="reference external" href="https://human-memory.net/brain-neurons-synapses/">neuronów</a>, które można postrzegać jako maleńkie  elementarne procesory. Otrzymują one sygnał poprzez <strong>dendryty</strong>, a jeśli jest on wystarczająco silny, jądro decyduje (obliczenie jest wykonane tutaj!) „wystrzelić” sygnał wyjściowy wzdłuż <strong>aksonu</strong>, gdzie jest on następnie przekazywany przez zakończenia aksonów do dendrytów innych neuronów. Połączenia aksonowo-dendryczne (połączenia <strong>synaptyczne</strong>) mogą być słabe lub silne, modyfikując przekazywany bodziec. Co więcej, siła połączeń synaptycznych może się zmieniać w czasie (<a class="reference external" href="https://en.wikipedia.org/wiki/Hebbian_theory">reguła Hebba</a> mówi nam, że połączenia stają się silniejsze, jeśli są używane wielokrotnie). W tym sensie neuron jest „programowalny”.</p>
<div class="figure align-default" id="neuron-fig">
<a class="reference internal image-reference" href="../_images/neuron-structure.jpg"><img alt="../_images/neuron-structure.jpg" src="../_images/neuron-structure.jpg" style="width: 450px;" /></a>
<p class="caption"><span class="caption-number">Rys. 1 </span><span class="caption-text">Biologiczny neuron (<a class="reference external" href="https://training.seer.cancer.gov/anatomy/nervous/tissue.html">https://training.seer.cancer.gov/anatomy/nervous/tissue.html</a>).</span><a class="headerlink" href="#neuron-fig" title="Stały odnośnik do tego obrazu">¶</a></p>
</div>
<p>Możemy zadać sobie pytanie, czy liczbę neuronów w mózgu rzeczywiście należy określać jako tak „ogromną”, jak się zwykle twierdzi. Porównajmy to do urządzeń obliczeniowych z układami pamięci. Liczba neuronów 10<span class="math notranslate nohighlight">\(^{11}\)</span> z grubsza odpowiada liczbie tranzystorów w chipie pamięci o pojemności 10 GB, co nie robi na nas specjalnego wrażenia, skoro w dzisiejszych czasach możemy kupić takie urządzenie za około 2$.</p>
<p>Co więcej, prędkość przemieszczania się impulsów nerwowych, która jest wynikiem procesów elektrochemicznych, również nie jest imponująca. Najszybsze sygnały, takie jak te związane z pobudzaniem mięśni, przemieszczają się z prędkością do 120 m/s (osłonki mielinowe są niezbędne do ich osiągnięcia). Sygnały dotykowe osiągają około 80m/s, podczas gdy ból jest przenoszony ze stosunkowo bardzo małymi prędkościami 0,6m/s. To dlatego kiedy upuszczasz młotek na palec u nogi, czujesz to natychmiast, ale ból dociera do mózgu z opóźnieniem ~1s, ponieważ musi pokonać odległość ~1,5m. Z drugiej strony, w urządzeniach elektronicznych sygnał przemieszcza się w przewodach z prędkością rzędu prędkości światła, <span class="math notranslate nohighlight">\(\sim 300000{\rm km/s}=3\razy 10^{8}{\rm m/ s}\)</span>!</p>
<p>W przypadku ludzi średni <a class="reference external" href="https://backyardbrains.com/experiments/reactiontime">czas reakcji</a> wynosi 0,25 s na bodziec wizualny, 0,17 s na bodziec dźwiękowy i 0,15 s na dotyk. W ten sposób ustawienie progowego czasu dla falstartu w sprintach na 0,1 s jest bezpiecznie poniżej możliwej reakcji biegacza. Są to niezwykle powolne reakcje w porównaniu z odpowiedziami elektronicznymi.</p>
<p>Na podstawie zużycia energii przez mózg można oszacować, że neuron kory mózgowej <a class="reference external" href="https://aiimpacts.org/rate-of-neuron-firing/">odpala</a> średnio raz na 6 sekund. Jest też mało prawdopodobne, aby przeciętny neuron odpalał częściej niż raz na sekundę. Pomnożenie tej szybkości wyzwalania przez liczbę wszystkich neuronów korowych, <span class="math notranslate nohighlight">\(\sim 1.6 \times 10^{10}\)</span>, daje około 3 <span class="math notranslate nohighlight">\(\times 10^{9}\)</span> wyładowań/s w korze, czyli 3GHz. To jest cżęstotliwość This aktowania typowego chipa procesora! Jeśli więc odpalanie neuronu utożsamić z elementarnym obliczeniem, to tak określona moc mózgu jest z grubsza porównywalna z mocą standardowego procesora komputerowego.</p>
<p>Powyższe fakty wskazują, że z punktu widzenia naiwnych porównań z chipami krzemowymi ludzki mózg nie jest niczym szczególnym. Co zatem daje nam nasze wyjątkowe zdolności: niesłychanie wydajne rozpoznawanie wzorców wizualnych i dźwiękowych, myślenie, świadomość, intuicję, wyobraźnię? Odpowiedź wiąże się z niesamowicie rozbudowaną architekturą mózgu, w której każdy neuron (jednostka procesora) jest połączony poprzez synapsy średnio aż z 10000 (!) innych neuronów. Ta cecha sprawia, że ​​jest ona radykalnie inna i znacznie bardziej skomplikowana niż architektura składająca się z jednostki sterującej, procesora i pamięci w naszych komputerach (architektura <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann_architecture">maszyny von Neumanna</a>) . Tam liczba połączeń jest rzędu liczby bitów pamięci, natomiast w ludzkim mózgu jest około <span class="math notranslate nohighlight">\(10^{15}\)</span> połączeń synaptycznych. Jak wspomniano, połączenia można „zaprogramować”, aby były silniejsze lub słabsze. Jeśli, dla prostego oszacowania, przybliżylibyśmy siłę połączenia tylko przez dwa stany synapsy, 0 lub 1, to całkowita liczba konfiguracji kombinatorycznych takiego systemu wynosiłaby <span class="math notranslate nohighlight">\(2^{10^{15}}\)</span> - „hiper-ogromna” liczba. Większość takich konfiguracji, oczywiście, nigdy nie jest realizowana w praktyce, niemniej jednak liczba możliwych stanów konfiguracyjnych mózgu lub „programów”, które może on realizować, jest naprawdę ogromna.</p>
<p>W ostatnich latach, wraz z rozwojem potężnych technik obrazowania, możliwe stało się mapowanie połączeń w mózgu z niespotykaną dotąd rozdzielczością, gdzie widoczne są pojedyncze wiązki nerwów. Wysiłki te są częścią [Projektu Human Connectome] (<a class="reference external" href="http://www.humanconnectomeproject.org">http://www.humanconnectomeproject.org</a>), którego ostatecznym celem jest dokłdne odwzorowanie architektury ludzkiego mózgu. W przypadku znacznie prostszej muszki owocowej, <a class="reference external" href="https://en.wikipedia.org/wiki/Drosophila_connectome">projekt drosophila connectome</a> jest bardzo zaawansowany.</p>
<div class="figure align-default" id="connectome-fig">
<a class="reference internal image-reference" href="../_images/brain.jpg"><img alt="../_images/brain.jpg" src="../_images/brain.jpg" style="width: 280px;" /></a>
<p class="caption"><span class="caption-number">Rys. 2 </span><span class="caption-text">Architektura mózgu włókna istoty białej (z projektu Human Connectome) <a class="reference external" href="http://www.humanconnectomeproject.org/gallery/">humanconnectomeproject.org</a>)</span><a class="headerlink" href="#connectome-fig" title="Stały odnośnik do tego obrazu">¶</a></p>
</div>
<div class="admonition important">
<p class="admonition-title">Ważne</p>
<p>Cecha „ogromnej łączności”, z miriadami neuronów służących jako równoległe procesory elementarne, sprawia, że ​​mózg jest zupełnie innym urządzeniem obliczeniowym niż <a class="reference external" href="https://en.wikipedia.org/wiki/Von_Neumann_architecture">maszyna von Neumanna</a> (tj. nasze codzienne komputery).</p>
</div>
</div>
<div class="section" id="sieci-feed-forward">
<h2>Sieci feed-forward<a class="headerlink" href="#sieci-feed-forward" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Neurofizjologiczne badania mózgu dostarczają ważnych wskazówek dla modeli matematycznych stosowanych w sztucznych sieciach neuronowych (<strong>ANN</strong>). I odwrotnie, postępy w algorytmice ANN często przybliżają nas do zrozumienia, jak faktycznie może działać nasz „komputer mózgowy”!</p>
<p>Najprostsze sieci ANN to tak zwane sieci <strong>feed forward</strong>, zilustrowane w <a class="reference internal" href="#ffnn-fig"><span class="std std-numref">Rys. 3</span></a>. Składają się one z warstwy <strong>wejściowej</strong> (czarne kropki), która reprezentuje tylko dane cyfrowe, oraz warstw neuronów (kolorowych kropek). Liczba neuronów w każdej warstwie może być różna. Złożoność sieci i zadań, które może ona realizować, rośnie rzecz jasna wraz z liczbą warstw i liczbą neuronów.</p>
<p>W dalszej części tego rozdziału podamy, w dość skondensownej postaci, kilka ważnych definicji:</p>
<p>Sieci z jedną warstwą neuronów nazywane są sieciami <strong>jednowarstwowymi</strong>. Ostatnia warstwa (jasnoniebieskie kropki) nazywana jest <strong>warstwą wyjściową</strong>. W sieciach wielowarstwowych (więcej niż jedna warstwa neuronowa) warstwy neuronowe poprzedzające warstwę wyjściową (fioletowe kropki) nazywane są <strong>warstwami pośrednimi</strong>. Jeśli liczba warstw jest duża (np. 64, 128, …), mamy do czynienia ze stosowanymi od niedawna „przełomowymi” <strong>głębokimi sieciami</strong>.</p>
<p>Neurony w różnych warstwach nie muszą działać w ten sam sposób, w szczególności neurony wyjściowe mogą zachowywać się inaczej niż pośrednie.</p>
<p>Sygnał z wejścia wędruje po wskazanych strzałkami łączach (krawędziach, połączeniach synaptycznych) do neuronów w kolejnych warstwach. W sieciach typu feed-forward, jak ta na <a class="reference internal" href="#ffnn-fig"><span class="std std-numref">Rys. 3</span></a>, sygnał może poruszać się tylko do przodu (na rysunku od lewej do prawej): od wejścia do pierwszej warstwy neuronowej, od pierwszej do drugiej, i tak dalej, aż do osiągnięcia wyjścia. Nie jest dozwolone cofanie się do poprzednich warstw ani równoległa propagacja pomiędzy neuronami tej samej warstwy. Byłaby to wówczas sieć z <strong>powracaniem</strong>, o czym nieco mówimy w rozdziale <a class="reference internal" href="som.html#lat-lab"><span class="std std-ref">Lateral inhibition</span></a>.</p>
<p>Jak szczegółowo opisujemy w kolejnych rozdziałach, wędrujący sygnał jest odpowiednio <strong>przetwarzany</strong> przez neurony, stąd urządzenie wykonuje obliczenia: wejście jest przekształcane w wyjście.</p>
<p>W przykładowej sieci <a class="reference internal" href="#ffnn-fig"><span class="std std-numref">Rys. 3</span></a> każdy neuron z poprzedniej warstwy jest połączony z każdym neuronem w następnej warstwie. Takie sieci ANN są nazywane <strong>w pełni połączonymi</strong>.</p>
<div class="figure align-default" id="ffnn-fig">
<a class="reference internal image-reference" href="../_images/feed_f.png"><img alt="../_images/feed_f.png" src="../_images/feed_f.png" style="width: 300px;" /></a>
<p class="caption"><span class="caption-number">Rys. 3 </span><span class="caption-text">Przykładowa, w pełni połączona sztuczna sieć neuronowa typu feed-forward. Kolorowe plamy reprezentują neurony, a krawędzie uskazują połączenia synaptyczne. Sygnał rozchodzi się od wejścia (czarne kropki), przez neurony w kolejnych warstwach pośrednich (ukrytych) (fioletowe kropki), do warstwy wyjściowej (jasnoniebieskie kropki). Siła połączeń jest kontrolowana przez wagi (hiperparametry) przypisane do krawędzi.</span><a class="headerlink" href="#ffnn-fig" title="Stały odnośnik do tego obrazu">¶</a></p>
</div>
<p>Jak omówimy bardziej szczegółowo późniwj, każda krawędź (połączenie synaptyczne) w sieci ma pewną „siłę” opisaną liczbą o nazwie <strong>waga</strong> (wagi są również określane jako <strong>hiperparametry</strong>). Nawet bardzo małe w pełni połączone sieci, takie jak ta z <a class="reference internal" href="#ffnn-fig"><span class="std std-numref">Rys. 3</span></a>, mają bardzo wiele połączeń (tutaj 30), stąd zawierają dużo hiperparametrów. Tak więc, choć czasami wyglądają niewinnie, ANN są w rzeczywistości bardzo złożonymi systemami wieloparametrycznymi. Co więcej, kluczową cechą jest tutaj nieliniowość odpowiedzi neuronów, co omawiamy w kolejnym rozdziale <a class="reference internal" href="mcp.html#mcp-lab"><span class="std std-ref">MCP Neuron</span></a>.</p>
</div>
<div class="section" id="dlaczego-python">
<h2>Dlaczego Python<a class="headerlink" href="#dlaczego-python" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Wybór języka <a class="reference external" href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python</a> dla prościutkich kodów tego kursu prawie nie wymaga wyjaśnienia. Zacytujmy tylko <a class="reference external" href="https://en.wikipedia.org/wiki/Tim_Peters_(software_engineer)">Tima Petersa</a>:</p>
<ul class="simple">
<li><p>Piękne jest lepsze niż brzydkie.</p></li>
<li><p>Jawne jest lepsze niż niejawne.</p></li>
<li><p>Proste jest lepsze niż złożone.</p></li>
<li><p>Złożone jest lepsze niż skomplikowane.</p></li>
<li><p>Liczy się czytelność.</p></li>
</ul>
<p>Według <a class="reference external" href="https://developer-tech.com/news/2021/apr/27/slashdata-javascript-python-boast-largest-developer-communities/">SlashData</a>, na świecie jest obecnie ponad 10 milionów programistów używających Pythona, zaraz po jezyku JavaScript (~14 milionów). W szczególności Python okazuje się bardzo praktyczny w zastosowaniach do sieci ANN.</p>
<div class="section" id="importowane-pakiety">
<h3>Importowane pakiety<a class="headerlink" href="#importowane-pakiety" title="Stały odnośnik do tego nagłówka">¶</a></h3>
<p>W trakcie tego kursu używamy kilku standardowych pakietów bibliotecznych Pythona do obliczeń numerycznych, wykresów itp. Jak podkreśliliśmy, nie korzystamy z żadnych bibliotek specjalnie dedykowanych sieciom neuronowym. Notebook każdego wykładu zaczyna się od zaimportowania niektórych z tych bibliotek:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>              <span class="c1"># numerical</span>
<span class="kn">import</span> <span class="nn">statistics</span> <span class="k">as</span> <span class="nn">st</span>         <span class="c1"># statistics</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> <span class="c1"># plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>        <span class="c1"># plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>      <span class="c1"># contour plots </span>

<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d.axes3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>   <span class="c1"># 3D plots</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Image</span><span class="p">,</span> <span class="n">HTML</span> <span class="c1"># display imported graphics</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-neural-package admonition">
<p class="admonition-title"><strong>neural</strong> package</p>
<p>Tworzone podczas tego kursu funkcje, które są później wielokrotnie używane, są umieszczane w pakiecie prywatnej biblioteki <strong>neural</strong>, opisanym w załączniku <a class="reference internal" href="appendix.html#app-lab"><span class="std std-ref">Pakiet neural</span></a>.</p>
</div>
<p>Zakładając, że pakiet znajduje się w podkatalogu względnym <strong>lib_nn</strong>, importujemy go w następujący sposób:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>                  <span class="c1"># system </span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;./lib_nn&#39;</span><span class="p">)</span> <span class="c1"># path to the lecture&#39;s package</span>

<span class="kn">from</span> <span class="nn">neural</span> <span class="kn">import</span> <span class="o">*</span>        <span class="c1"># import the lecture&#39;s package</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Invoking __init__.py for neural
</pre></div>
</div>
</div>
</div>
<p>Więcej informacji można znaleźć w dodatku <a class="reference internal" href="appendix.html#app-lab"><span class="std std-ref">Pakiet neural</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Informacja</p>
<p>Dla zwięzłości prezentacji, niektóre zbędne (np. import bibliotek) lub nieistotne fragmenty kodu są obecne tylko w notebookach Jupytera (do pobrania) i nie są ukazywane w książce. Dzięki temu tekst jest krótszy i czytelny.</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index.html" title="wstecz strona">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">wstecz</p>
            <p class="prev-next-title">Sieci neuronowe dla początkujących w Pythonie: wykłady w Jupyter Book</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="mcp.html" title="dalej strona">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">dalej</p>
        <p class="prev-next-title">MCP Neuron</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Przez Wojciech Broniowski<br/>
    
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>